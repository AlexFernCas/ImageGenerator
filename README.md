# ğŸ¨ Generador de ImÃ¡genes con Hugging Face Diffusers
En este proyecto se ha implementado una aplicaciÃ³n de generaciÃ³n de imÃ¡genes a partir de texto (text-to-image) usando modelos preentrenados de **Stable Diffusion** y la librerÃ­a **Hugging Face Diffusers**, con una interfaz grÃ¡fica creada en Gradio.

Incluye todo el flujo: desde la configuraciÃ³n del entorno y carga del modelo hasta la inferencia y visualizaciÃ³n de imÃ¡genes generadas.

---


# ğŸš€ Uso

### Paso 1. EjecuciÃ³n del generador:

```bash
python src/main.py
```

Se pondrÃ¡ en marcha un servidor web Gradio, por defecto en el puerto 7860.

<img src="./media/interfaz_0.png" controls width="600">

**Flujo:**

* Escribir una descripciÃ³n (prompt) en la caja de texto de la interfaz.

* Pulsar "Generar".

* Esperar unos segundos mientras el modelo procesa la entrada.

* Visualizar y descargar la imagen generada.

<img src="./media/interfaz_1.png" controls width="600">

---

# ğŸ–¼ï¸ ImÃ¡genes generadas

Prompt: "Persona haciendo surf en el desierto."

<img src="./media/imagen_1.png" controls width="600">

Prompt: "Perro haciendo surf en el desierto."

<img src="./media/imagen_2.png" controls width="600">

Prompt: "Perro haciendo surf en el desierto."

<img src="./media/imagen_3.png" controls width="600">

El modelo genera imÃ¡genes muy ajustadas al prompt introducido y, al mismo tiempo, puede producir resultados distintos con el mismo prompt, mostrando su variabilidad creativa.

# âœ¨ CaracterÃ­sticas principales

Uso de Stable Diffusion preentrenado para generaciÃ³n de imÃ¡genes de alta calidad.

Interfaz grÃ¡fica simple y amigable con Gradio.

Posibilidad de ajustar el guidance scale y la resoluciÃ³n para personalizar resultados.

CÃ³digo modular y fÃ¡cilmente ampliable para aÃ±adir filtros o procesamientos extra.

Uso directo de modelos preentrenados sin necesidad de entrenamiento desde cero.

---


# ğŸ“ Estructura del proyecto

La carpeta principal incluye todo lo necesario para reproducir el generador:

src/main.py         â†’ Script principal que lanza la interfaz y ejecuta la inferencia.

data/               â†’ Carpeta opcional para guardar imÃ¡genes generadas.

requirements.txt    â†’ Lista de dependencias necesarias.

media/              â†’ Recursos multimedia para documentaciÃ³n (gifs, capturas).

---


# ğŸ› ï¸ InstalaciÃ³n

### Requisitos previos

Python 3.10 instalado

### Crear entorno virtual

```bash
python -m venv venv

source venv/bin/activate   # En Linux/Mac

venv\Scripts\activate      # En Windows
```

### Instalar dependencias

```bash
pip install -r requirements.txt
```

---

# ğŸ” TecnologÃ­as y habilidades

**Lenguajes:** Python  

**Frameworks/LibrerÃ­as:** Hugging Face Diffusers, Gradio, FastAPI  

**Herramientas:** Git, entornos virtuales, pip  

**Ãreas de IA:** Text-to-Image, modelos generativos, optimizaciÃ³n de inferencia

---


# ğŸ“Œ Notas

La primera ejecuciÃ³n descargarÃ¡ el modelo desde Hugging Face, por lo que puede tardar varios minutos.

La calidad y coherencia de las imÃ¡genes dependen en gran parte de la calidad y detalle del prompt.

Si usas GPU, la generaciÃ³n serÃ¡ mucho mÃ¡s rÃ¡pida.

El proyecto no incluye imÃ¡genes generadas por defecto; se pueden guardar en la carpeta data/.

---


# ğŸ“œ Licencia

Uso educativo y de demostraciÃ³n. El modelo Stable Diffusion tiene su propia licencia y restricciones de uso, revisa los tÃ©rminos en Hugging Face.